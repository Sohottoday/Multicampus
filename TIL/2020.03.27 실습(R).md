# 2020.03.27 실습

## R

### 실습 1

```R

#다음 실습은 정적 크롤링(스크래핑)의 수행평가입니다. 구현한 다음 saramin.R과 
#saramin.csv 를 이름.zip 파일로 압축해서 메일로 제출하세요.
#(unicodaum@hanmail.net)
#그리고 이 파일들은 잘 보관하세요… NCS 시스템에도 올려야 하니깐요.
#다음은 “Java”로 검색한 사람인 페이지의 화면이다.
#http://www.saramin.co.kr/zf_user/search?search_area=main&search_done=y&search_optional_item=n&searchType=default_mysearch&searchword=Java
#
#빨간 박스의 내용을 추출하여 CSV 파일(파일명:saramin.csv)로 저장하는데
#첫 번째 열은 기술이름(tech_name), 두 번째 열을 채용 정보 건수(info_count)로 구성한다.
#구현된 R 소스는 saramin.R 로 제출한다.

url<-"http://www.saramin.co.kr/zf_user/search?search_area=main&search_done=y&search_optional_item=n&searchType=default_mysearch&searchword=Java"
text<-read_html(url)
text

nodes1 <- html_nodes(text,".lbl_sfilter>.txt")
tech_name<-html_text(nodes1)
tech_name<-gsub("#","",tech_name)
tech_name

nodes2 <- html_nodes(text,".lbl_sfilter>.count")
info_count<-html_text(nodes2)
#info_count<-gsub("[[:punct:]]","",info_count)
info_count<-gsub("\\(","",info_count)
info_count<-gsub("\\)","",info_count)
info_count

if(length(tech_name>length(info_count))) {
  length(tech_name)<-length(info_count)
}

saramin_frame<-data.frame("기술이름(tech_name)"=tech_name, "채용 정보 건수(info_count)"=info_count)

write.csv(saramin_frame, file = "saramin.csv")



```

---



### 실습 2

```R
#다음의 요구 사항대로 구현하고 모든 소스와 생성된 csv 파일을 제출한다.
#다음은 https://comic.naver.com/genre/bestChallenge.nhn 사이트의 콘텐츠 일부이다.
#박스로 표시된 내용을 추출하고 “comicName,  comicSummary, comicGrade” 
#열명으로 DataFrame을 생성하여
#navercomic.csv로 저장하고 소스는 navercomic.R로 저장한다. 
#모든 페이지를 크롤링하고 스크래핑한다.

site<-"https://comic.naver.com/genre/bestChallenge.nhn?&page="
text<-NULL
comic<-NULL
comicall<-NULL
for(n in 1:200){
  url<-paste(site,n,sep="")
  text<-read_html(url)
  nodes1 <- html_nodes(text,".challengeInfo>.challengeTitle")
  comicName <- html_text(nodes1)
  nodes2 <- html_nodes(text, ".challengeInfo>.summary")
  comicSummary <- html_text(nodes2)
  nodes3 <- html_nodes(text, ".challengeInfo>.rating_type>strong")
  comicGrade <- html_text(nodes3)
  comic<-cbind(comicName,comicSummary,comicGrade)
  comicall<-rbind(comicall,comic)
  
}
write.csv(comicall, file="navercomic.csv")


```

---



### 실습 3

```R
#제시된 memo.txt 파일을 행 단위로 읽어서 벡터를 리턴한다.
#벡터를 구성하고 있는 각 원소들의 내용을 확인한 후에 아래에 제시된 결과로
#변경되도록 문자 또는 문자열 변경을 시도한다. (gsub() 사용)
#원소마다 변경해야 하는 룰이 다르므로 원소마다 처리한다.
#처리된 결과를 memo_new.txt 파일에 저장한다. (write() 함수 사용)
#구현소스는 textmining1.R 로 저장하여 생성된 memo_new.txt 파일로 함께 제출한다.


scan("data/memo.txt",what = "",encoding="UTF-8")

memo1<-readLines("data/memo.txt", encoding = "UTF-8")
memo1
memo1[1]<-gsub("[[:punct:]]","",memo1[1])
memo1[2]<-gsub("e","E",memo1[2])
memo1[3]<-gsub("[[:digit:]]","",memo1[3])
memo1[4]<-gsub("[A-z]","",memo1[4]) #gsub("[[:upper:][:lower:]]","",memo1[4])  gsub("[A-Za-z]","",memo1[4])
memo1[5]<-gsub("[[:digit:][:punct:]]","",memo1[5])
memo1[6]<-gsub("[^가-힣]","",memo1[6])
memo1[7]<-gsub("YOU","you",memo1[7])
memo1[7]<-gsub("OK","ok",memo1[7])
length(memo1)<-7


write.table(memo1,file = "memo_new.txt")


```

---



### 실습 4

```R
#네이버 웹툰 댓글 페이지에서 
#베스트 댓글과 전체 댓글 50페이지를 읽어서 webtoon1.txt 파일에 저장(write())하는 
#코드를 작성한다. 
#제출 파일명 : webtoon1.txt, webtoon1.R

install.packages("RSelenium")
library(RSelenium)
remDr<-remoteDriver(remoteServerAddr="localhost",port=4445,browserName="chrome")
remDr$open()
url<-'http://comic.naver.com/comment/comment.nhn?titleId=570503&no=135'
remDr$navigate(url)

alldat_frame<-NULL

bestReview<-remDr$findElements(using = "css selector","ul.u_cbox_list span.u_cbox_contents")
bestReviewText<-sapply(bestReview,function(x){x$getElementText()})
bestReviewText<-unlist(bestReviewText)
alldat_frame<-c(alldat_frame,bestReviewText)
datall<-remDr$findElement(using = "css","#cbox_module > div > div.u_cbox_sort > div.u_cbox_sort_option > div > ul > li:nth-child(2) > a")
datall$clickElement()
Sys.sleep(1)
normaldat<-remDr$findElements(using = "css selector","ul.u_cbox_list span.u_cbox_contents")
normaldatText<-sapply(normaldat,function(x){x$getElementText()})
normaldatText<-unlist(normaldatText)
alldat_frame<-append(alldat_frame,normaldatText)

for(i in 1:5) {
  for(n in 4:13) {
    if(n>=4 & n<=12) {
      next_daum<-paste0("#cbox_module>div>div.u_cbox_paginate>div> a:nth-child(",n,") > span")
      next_daumpage<-remDr$findElement(using = "css",next_daum)
      next_daumpage$clickElement()
      Sys.sleep(1)
      normaldat<-remDr$findElements(using = "css selector","ul.u_cbox_list span.u_cbox_contents")
      normaldatText<-sapply(normaldat,function(x){x$getElementText()})
      normaldatText<-unlist(normaldatText)
      alldat_frame<-append(alldat_frame,normaldatText)
   
   } else if(n==13) {
      next_daum<-paste0("#cbox_module>div>div.u_cbox_paginate>div> a:nth-child(",n,") > span")
      next_daumpage<-remDr$findElement(using = "css",next_daum)
      next_daumpage$clickElement()
      Sys.sleep(1)
        if(i<=4){
          normaldat<-remDr$findElements(using = "css selector","ul.u_cbox_list span.u_cbox_contents")
          normaldatText<-sapply(normaldat,function(x){x$getElementText()})
          normaldatText<-unlist(normaldatText)
          alldat_frame<-append(alldat_frame,normaldatText)
        }
    }
  }
}

write.table(alldat_frame,file = "webtoon1.txt")

#cbox_module > div > div.u_cbox_paginate > div > a:nth-child(3)
#cbox_module > div > div.u_cbox_paginate > div > a:nth-child(4)
#cbox_module > div > div.u_cbox_paginate > div > a:nth-child(4) 1페이지
#cbox_module > div > div.u_cbox_paginate > div > a:nth-child(12) 10페이지

#cbox_module > div > div.u_cbox_paginate > div > a:nth-child(13) 다음
#cbox_module > div > div.u_cbox_paginate > div > a:nth-child(4)

```

