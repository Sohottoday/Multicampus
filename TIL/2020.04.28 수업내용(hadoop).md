# 2020.04.28 수업내용

## Linux 에서의 hadoop 셋팅

### hadoop

- 기존의 데이터 처리는 분산 시키는 것은 있었으나 분산 처리하는 시스템은 없었음.
- 기존의 데이터 처리는 분산된 데이터를 한곳에 모아서 한곳에서 처리하는 방식
- 하둡은 분산된 상태에서 처리까지 가능



- HDFS : hadoop distributed file system
- MapReduce



![img](C:\Users\student\Desktop\Typora img\99FCA7405AD3BA2106.jpg)

![img](C:\Users\student\Desktop\Typora img\996B9D3C5AD3B9FD05.jpg)

- Hadoop & Eco System
  - 실질적 하둡
    - YARN/Map Reduce V2
    - Hadoop Distributed File System
  - Eco System
    - Pig(Scripting)
    - Hive(SQL)
    - Mahout(ML)
    - Oozie(Workflow)

- 클러스터 : 여러 대의 컴퓨터들이 연결되어 하나의 시스템처럼 동작하는 컴퓨터들의 집합
- 분산 컴퓨팅 시스템
- Hadoop Cluster 구조

![setup your hadoop cluster and mapreduce bigdata programs for visual analysis](C:\Users\student\Desktop\Typora img\setup-your-hadoop-cluster-and-mapreduce-bigdata-programs-for-visual-analysis.jpg)



- Data Block -블록 사이즈(디폴트 : 128M) (64M는 하둡 1.0 버전 시절)

![block-replication-on-hdfs-3-638](C:\Users\student\Desktop\Typora img\block-replication-on-hdfs-3-638.jpg)

- Hadoop HDFS 명령어
  - hdfs dfs -ls /[디렉토리명 또는 파일명] : 지정된 디렉토리의 파일리스트 또는 지정된 파일의 정보를 보여준다.
  - hdfs dfs -lsr /[디렉토리명] : 지정된 디렉토리의 파일리스트 및 서브티렉토리들의 파일 리스트도 보여준다.
  - hdfs dfs -mkdir /[디렉토리명] : 지정된 디렉토리를 생성한다.
  - hdfs dfs -cat /[디렉토리/]파일 : 지정된 파일의 내용을 화면에 출력한다.
  - hdfs dfs -put 사용자계정로컬파일 HDFS디렉토리[/파일] : 지정된 HDFS상의 파일을 사용자계정 로컬 파일시스템의 디렉토리나 파일로 복사한다.
  - hdfs dfs -rm /[디렉토리]/파일 : 지정된 파일을 삭제한다.
  - hdfs dfs -rmr /디렉토리 : 지정된 디렉토리를 삭제. 비어 있지않은 디렉토리도 삭제하며 서브 디렉토리도 삭제한다.
  - hdfs dfs -tail /[디렉토리]/파일 : 지정된 파일이 마지막 1kb 내용을 화면에 출력한다.
  - hdfs dfs -chmod 사용자허가모드 /[디렉토리명 또는 파일명] : 지정된 디렉토리 또는 파일의 사용자 허가 모드를 변경한다.



![image-20200428175911050](C:\Users\student\Desktop\Typora img\image-20200428175124050.png)

7. hadoop_env.sh 파일 끝에 다음 내용을 추가한다.
export JAVA_HOME=/usr/local/java
export HADOOP_HOME=/root/hadoop-2.7.7
export HADOOP_HEAPSIZE=500

8. mapred_env.sh 파일 끝에 다음 내용을 추가한다.
export JAVA_HOME=/usr/local/java
export HADOOP_JOB_HISTORYSERVER_HEAPSIZE=500
export HADOOP_HOME=/root/hadoop-2.7.7

9. yarn_env.sh 파일 끝에 다음 내용을 추가한다.
export JAVA_HOME=/usr/local/java
export HADOOP_HOME=/root/hadoop-2.7.7
export YARN_HEAPSIZE=500

10. core-site.xml 에 다음 내용을 편집한다.
<configuration>
      <property>
      <name>fs.defaultFS</name>
      <value>hdfs://master:9000/</value>
      </property>   
</configuration>

11. hdfs-site.xml 에 다음 내용을 편집한다.
<configuration>
      <property>
      <name>dfs.replication</name>
      <value>3</value>
      </property>
      <property>
      <name>dfs.name.dir</name>
      <value>/root/hadoop-2.7.7/hdfs/name</value>
      </property>
      <property>
      <name>dfs.data.dir</name>
      <value>/root/hadoop-2.7.7/hdfs/data</value>
      </property>
      <property>
      <name>dfs.support.append</name>
      <value>true</value>
      </property>
      <property>
      <name>dfs.namenode.secondary.http-address</name>
      <value>slave1:50090</value>
      </property>
      <property>
      <name>dfs.namenode.secondary.https-address</name>
      <value>slave1:50091</value>
      </property> 
</configuration>

12. mapred-site.xml 에 다음 내용을 편집한다.
<configuration>
      <property>
      <name>mapreduce.framework.name</name>
      <value>yarn</value>
      </property>
      <property>
      <name>yarn.resourcemanager.hostname</name>
      <value>master</value>
      </property>
</configuration>

13. yarn-site.xml 에 다음 내용을 편집한다. 
<configuration>
<!-- Site specific YARN configuration properties -->
      <property>
      <name>yarn.nodemanager.aux-services</name>
      <value>mapreduce_shuffle</value>
      </property>
</configuration>

![image-20200428180055655](C:\Users\student\Desktop\Typora img\12123124123)

![image-20200428180207243](C:\Users\student\Desktop\Typora img\11122221111)





p.s

echo	:	확인한다는 의미

./eclipse	:	이클립스 기동( 꼭 tools에서 실행시킬 필요는 없음.)